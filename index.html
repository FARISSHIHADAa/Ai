<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Drone AI Demo</title>
    <style>
        body { margin: 0; }
        canvas { display: block; }
    </style>
</head>
<body>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>
    <script>
        let scene, camera, renderer, droneMesh;
        let model;
        
        // Initialize Three.js scene
        function init() {
            scene = new THREE.Scene();
            camera = new THREE.PerspectiveCamera(75, window.innerWidth/window.innerHeight, 0.1, 1000);
            renderer = new THREE.WebGLRenderer();
            renderer.setSize(window.innerWidth, window.innerHeight);
            document.body.appendChild(renderer.domElement);

            // Create a simple drone mesh (cube)
            const geometry = new THREE.BoxGeometry(1, 1, 1);
            const material = new THREE.MeshBasicMaterial({ color: 0x00ff00 });
            droneMesh = new THREE.Mesh(geometry, material);
            scene.add(droneMesh);

            camera.position.z = 5;

            // Load the Coco-SSD model
            cocoSsd.load().then((loadedModel) => {
                model = loadedModel;
                detectObjects();
            });

            animate();
        }

        // Animation loop
        function animate() {
            requestAnimationFrame(animate);
            droneMesh.rotation.x += 0.01;
            droneMesh.rotation.y += 0.01;
            renderer.render(scene, camera);
        }

        // Object detection using TensorFlow.js
        async function detectObjects() {
            const videoElement = document.createElement('video');
            videoElement.width = 640;
            videoElement.height = 480;
            videoElement.autoplay = true;

            const stream = await navigator.mediaDevices.getUserMedia({ video: true });
            videoElement.srcObject = stream;

            const canvas = document.createElement('canvas');
            const context = canvas.getContext('2d');
            document.body.appendChild(canvas);
            canvas.width = 640;
            canvas.height = 480;

            function detect() {
                context.drawImage(videoElement, 0, 0, canvas.width, canvas.height);
                model.detect(canvas).then(predictions => {
                    predictions.forEach(prediction => {
                        context.beginPath();
                        context.rect(prediction.bbox[0], prediction.bbox[1], prediction.bbox[2], prediction.bbox[3]);
                        context.lineWidth = 2;
                        context.strokeStyle = 'red';
                        context.fillStyle = 'red';
                        context.stroke();
                        context.fillText(prediction.class, prediction.bbox[0], prediction.bbox[1] > 10 ? prediction.bbox[1] - 5 : 10);
                    });
                    requestAnimationFrame(detect);
                });
            }
            detect();
        }

        // Initialize the demo
        init();
    </script>
</body>
</html>
